{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b0fea63-bcb8-4e51-9e6f-1bdcbe5d6b0e",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after 'for' statement on line 6 (3854838988.py, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[1], line 7\u001b[1;36m\u001b[0m\n\u001b[1;33m    text = quote.find('span', class_='text').text\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block after 'for' statement on line 6\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "# Function to scrape quotes from a page\n",
    "def scrape_page(soup, quotes):\n",
    " for quote in soup.find_all('div', class_='quote'):\n",
    " text = quote.find('span', class_='text').text\n",
    " author = quote.find('small', class_='author').text\n",
    " tags = ', '.join(tag.text for tag in quote.find_all('a', class_='tag'))\n",
    " quotes.append({'Text': text, 'Author': author, 'Tags': tags})\n",
    "# Base URL and headers\n",
    "base_url = 'https://quotes.toscrape.com'\n",
    "headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "# List to store quotes\n",
    "quotes = []\n",
    "# Function to scrape quotes from multiple pages\n",
    "def scrape_all_pages(url):\n",
    " while url:\n",
    " response = requests.get(url, headers=headers)\n",
    " soup = BeautifulSoup(response.text, 'html.parser')\n",
    " scrape_page(soup, quotes)\n",
    " next_page = soup.find('li', class_='next')\n",
    " url = base_url + next_page.find('a')['href'] if next_page else None\n",
    "# Scrape quotes from all pages\n",
    "scrape_all_pages(base_url)\n",
    "# Save quotes to CSV file\n",
    "with open('quotes2.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
    " writer = csv.DictWriter(csvfile, fieldnames=['Text', 'Author', 'Tags'])\n",
    " writer.writeheader()\n",
    " writer.writerows(quotes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5484828b-1823-460c-9ab1-4a1d5055ba3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quotes have been saved to quotes2.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "\n",
    "# Function to scrape quotes from a page\n",
    "def scrape_page(soup, quotes):\n",
    "    for quote in soup.find_all('div', class_='quote'):\n",
    "        text = quote.find('span', class_='text').text\n",
    "        author = quote.find('small', class_='author').text\n",
    "        tags = ', '.join(tag.text for tag in quote.find_all('a', class_='tag'))\n",
    "        quotes.append({'Text': text, 'Author': author, 'Tags': tags})\n",
    "\n",
    "# Base URL and headers\n",
    "base_url = 'https://quotes.toscrape.com'\n",
    "headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "\n",
    "# List to store quotes\n",
    "quotes = []\n",
    "\n",
    "# Function to scrape quotes from multiple pages\n",
    "def scrape_all_pages(url):\n",
    "    while url:\n",
    "        response = requests.get(url, headers=headers)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        scrape_page(soup, quotes)\n",
    "        next_page = soup.find('li', class_='next')\n",
    "        url = base_url + next_page.find('a')['href'] if next_page else None\n",
    "\n",
    "# Scrape quotes from all pages\n",
    "scrape_all_pages(base_url)\n",
    "\n",
    "# Save quotes to CSV file\n",
    "with open('quotes2.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=['Text', 'Author', 'Tags'])\n",
    "    writer.writeheader()\n",
    "    writer.writerows(quotes)\n",
    "\n",
    "print(\"Quotes have been saved to quotes2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2a7be8-f458-4775-ad1e-75b7eb85be0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
