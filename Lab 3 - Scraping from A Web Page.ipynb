{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e4ffbb0-6128-4b49-a51f-51f9bdd23689",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after 'for' statement on line 28 (631384942.py, line 29)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[1], line 29\u001b[1;36m\u001b[0m\n\u001b[1;33m    step = step_element.find('p', class_='CDt4Ke zfr3Q')\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block after 'for' statement on line 28\n"
     ]
    }
   ],
   "source": [
    "#importing required libraries\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "#to identify the target URL to scrape\n",
    "url = \"https://sites.google.com/view/cisb5123/home\"\n",
    "#to request to download the data from the target URL\n",
    "page = requests.get(url)\n",
    "#Parse and Transform\n",
    "#to parse the downloaded data\n",
    "data = BeautifulSoup (page.content, 'html.parser')\n",
    "#to print the downloaded data - optional\n",
    "print (data)\n",
    "print ('\\n')\n",
    "# Extracting title and subtitle\n",
    "title = data.find('h1').strong.get_text()\n",
    "subtitle = data.find('h2').span.get_text()\n",
    "# Extracting introduction paragraph\n",
    "intro_text = data.find(text=\"Introduction\")\n",
    "intro = data.find('p').span.get_text()\n",
    "#to find all the ordered list by specifying its class name\n",
    "step_elements = data.find_all('li', class_='TYR86d zfr3Q')\n",
    "#to write the extracted data into a text file\n",
    "with open(\"extracted_data2.txt\", \"w\", encoding=\"utf-8\") as file:\n",
    " file.write(\"Title: {}\\n\".format(title))\n",
    " file.write(\"Subtitle: {}\\n\".format(subtitle))\n",
    " file.write(\"Introduction: {}\\n\".format(intro))\n",
    " file.write(\"Steps:\\n\")\n",
    " for step_element in step_elements:\n",
    " step = step_element.find('p', class_='CDt4Ke zfr3Q')\n",
    " file.write(\"- {}\\n\".format(step.text))\n",
    "print(\"Data has been saved to extracted_data.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06b75d33-8eff-412e-9dfb-39d84c24d53d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been saved to extracted_data2.txt\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Target URL to scrape\n",
    "url = \"https://sites.google.com/view/cisb5123/home\"\n",
    "\n",
    "# Request to download the data from the target URL\n",
    "page = requests.get(url)\n",
    "\n",
    "# Parse and Transform\n",
    "# Parse the downloaded data\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "# Extracting title and subtitle\n",
    "try:\n",
    "    title = soup.find('h1').get_text(strip=True)\n",
    "    subtitle = soup.find('h2').get_text(strip=True)\n",
    "except AttributeError:\n",
    "    title = \"Title not found\"\n",
    "    subtitle = \"Subtitle not found\"\n",
    "\n",
    "# Extracting introduction paragraph\n",
    "intro = \"\"\n",
    "intro_element = soup.find('p')\n",
    "if intro_element:\n",
    "    intro = intro_element.get_text(strip=True)\n",
    "else:\n",
    "    intro = \"Introduction not found\"\n",
    "\n",
    "# Finding all step elements\n",
    "steps = []\n",
    "step_elements = soup.find_all('li')\n",
    "for step_element in step_elements:\n",
    "    step_text = step_element.get_text(strip=True)\n",
    "    if step_text:\n",
    "        steps.append(step_text)\n",
    "\n",
    "# Writing extracted data into a text file\n",
    "with open(\"extracted_data2.txt\", \"w\", encoding=\"utf-8\") as file:\n",
    "    file.write(f\"{title}\\n\")\n",
    "    file.write(f\"{subtitle}\\n\\n\")\n",
    "    file.write(\"Introduction\\n\")\n",
    "    file.write(f\"{intro}\\n\\n\")\n",
    "    file.write(\"Steps in web scraping:\\n\\n\")\n",
    "    for step in steps:\n",
    "        file.write(f\"{step}\\n\\n\")\n",
    "\n",
    "print(\"Data has been saved to extracted_data2.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6050f330-3c0e-46e0-8790-fc304ce617cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
